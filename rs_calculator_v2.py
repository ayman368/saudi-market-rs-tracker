import pandas as pd
import numpy as np
from sqlalchemy.orm import Session
from sqlalchemy import desc
from app.models.price import Price
from app.models.rs_daily import RSDaily
import logging
import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def calculate_and_save_rs_v2(db: Session, target_date=None):
    """
    Ø­Ø³Ø§Ø¨ RS Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙØ¹Ù„ÙŠØ© (Trading Days Sequence).
    ÙŠØ·Ø§Ø¨Ù‚ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥ÙƒØ³Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:
    1. Seq = Ø¹Ø¯Ø§Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„ÙƒÙ„ Ø³Ù‡Ù….
    2. Shift 63/126/189/252 ÙŠÙˆÙ… ØªØ¯Ø§ÙˆÙ„ (Ù…Ø´ Ø£ÙŠØ§Ù… ØªÙ‚ÙˆÙŠÙ…).
    3. RS Raw = Ù…ØªÙˆØ³Ø· Ù…ÙˆØ²ÙˆÙ†.
    4. RS Rating = ØªØ±ØªÙŠØ¨ Ù…Ø¦ÙˆÙŠ ÙŠÙˆÙ…ÙŠ (1-99).
    """
    logger.info("ğŸ”„ Starting RS Calculation V2 (Trading Days Logic)...")
    
    # 1. Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
    # Ù…Ù„Ø­ÙˆØ¸Ø©: Ù„Ø§Ø²Ù… Ù†Ø¬ÙŠØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙƒÙ„Ù‡ Ø¹Ø´Ø§Ù† Ù†Ø­Ø³Ø¨ Ø§Ù„Ù€ Seq ÙˆØ§Ù„Ù€ Shifts ØµØ­
    query = db.query(
        Price.date,
        Price.symbol,
        Price.close,
        Price.company_name
        # Ù…Ù…ÙƒÙ† Ù†Ø­ØªØ§Ø¬ volume Ù„Ùˆ Ù‡Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹
    ).order_by(Price.symbol, Price.date)
    
    prices = query.all()
    
    if not prices:
        logger.warning("âš ï¸ No price data found in database.")
        return

    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ DataFrame
    df = pd.DataFrame([{
        'date': p.date,
        'symbol': p.symbol,
        'close': float(p.close),
        'company_name': p.company_name
    } for p in prices])
    
    logger.info(f"ğŸ“Š Loaded {len(df)} price records.")

    # 2. Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Trading Logic)
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹ Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ Shift ÙŠØ´ØªØºÙ„ ØµØ­
    df = df.sort_values(by=['symbol', 'date'])
    
    # Group By Symbol Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ù„ÙƒÙ„ Ø³Ù‡Ù… Ø¹Ù„Ù‰ Ø­Ø¯Ø©
    # ØªÙƒØ§ÙØ¦: Ø­Ø³Ø§Ø¨ Seq Ù„ÙƒÙ„ Ø³Ù‡Ù…
    df['seq'] = df.groupby('symbol').cumcount() + 1
    
    # Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ù…Ø¹ Shift (Ø¥Ø²Ø§Ø­Ø© ØµÙÙˆÙ)
    # R3M = Price / Price(shifted 63 rows) - 1
    def calc_return(series, days):
        return (series / series.shift(days)) - 1

    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ù„ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© (Ø³Ù‡Ù…)
    grouped = df.groupby('symbol')['close']
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹ÙˆØ§Ø¦Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (63, 126, 189, 252)
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© (Ù…Ø«Ù„Ø§Ù‹ Ø³Ù‡Ù… Ø¬Ø¯ÙŠØ¯)ØŒ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø³ØªÙƒÙˆÙ† NaN
    df['return_3m'] = grouped.transform(lambda x: calc_return(x, 63))
    df['return_6m'] = grouped.transform(lambda x: calc_return(x, 126))
    df['return_9m'] = grouped.transform(lambda x: calc_return(x, 189))
    df['return_12m'] = grouped.transform(lambda x: calc_return(x, 252))

    # 3. Ø­Ø³Ø§Ø¨ RS Raw (Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙˆØ²ÙˆÙ†)
    # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…): 
    # Ù†Ø³ØªØ®Ø¯Ù… "Weighted Ranks" Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† "Weighted Returns" Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹
    # Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹ÙˆØ§Ø¦Ø¯ Ø§Ù„Ø®Ø§Ù… (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ)
    df['rs_raw_from_returns'] = (
        (0.20 * df['return_12m']) +
        (0.20 * df['return_9m']) +
        (0.20 * df['return_6m']) +
        (0.40 * df['return_3m'])
    )
    
    # ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ RS Raw (Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹)
    # ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¥Ø¨Ù‚Ø§Ø¡Ù‡Ø§ Ø¨Ù‚ÙŠÙ… Null Ø£Ùˆ Ø­Ø°ÙÙ‡Ø§ Ù…Ù† Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù€ Rank
    
    # 4. Ø­Ø³Ø§Ø¨ RS Rating (Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø¦ÙˆÙŠ Ø§Ù„ÙŠÙˆÙ…ÙŠ) ÙˆØ´Ù…Ù„ Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„ÙƒÙ„ ÙØªØ±Ø©
    def calculate_daily_rank(day_group):
        valid_rs = day_group.dropna()
        if valid_rs.empty:
            return pd.Series(index=day_group.index, dtype=float)
        ranks = valid_rs.rank(pct=True) * 100
        return ranks.round(0).clip(lower=1, upper=99).astype(int)

    # ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„ÙƒÙ„ ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ© (Ø¹Ø´Ø§Ù† Ù†Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø²ÙŠ Ø§Ù„ØµÙˆØ±Ø©)
    logger.info("âš¡ Calculating Ranks per period...")
    
    df['rank_3m'] = df.groupby('date')['return_3m'].transform(calculate_daily_rank)
    df['rank_6m'] = df.groupby('date')['return_6m'].transform(calculate_daily_rank)
    df['rank_9m'] = df.groupby('date')['return_9m'].transform(calculate_daily_rank)
    df['rank_12m'] = df.groupby('date')['return_12m'].transform(calculate_daily_rank)

    # Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø­Ø³Ø§Ø¨ RS Raw Ù…Ù† Ø§Ù„Ù€ Ranks (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Int64 nullable Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
    df['rs_raw'] = (
        (0.20 * df['rank_12m'].astype('float')) +
        (0.20 * df['rank_9m'].astype('float')) +
        (0.20 * df['rank_6m'].astype('float')) +
        (0.40 * df['rank_3m'].astype('float'))
    )

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ RS Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    df['rs_rating'] = df.groupby('date')['rs_raw'].transform(calculate_daily_rank)
    
    # Ù„Ùˆ Ø­Ø¯Ø¯Ù†Ø§ target_date (Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹)ØŒ Ù†ØµÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¯Ù„ÙˆÙ‚ØªÙŠ
    if target_date:
        logger.info(f"Filtering for date: {target_date}")
        # convert target_date to match dataframe date type if useful
        result_df = df[df['date'] == target_date].copy()
    else:
        # Ù„Ùˆ Ù…ÙÙŠØ´ ØªØ§Ø±ÙŠØ®ØŒ Ù†Ø­Ø¯Ø« Ø§Ù„ÙƒÙ„ (Ø£Ùˆ Ø¢Ø®Ø± ÙØªØ±Ø©)
        # Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ù…Ù„Ø§ÙŠÙŠÙ† Ø§Ù„Ø³Ø¬Ù„Ø§ØªØŒ Ù…Ù…ÙƒÙ† Ù†Ø­Ø¯Ø« Ø¢Ø®Ø± Ø³Ù†Ø© Ø¨Ø³ØŸ
        # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø·Ù„Ø¨ Ø³ÙƒØ±ÙŠØ¨Øª ÙƒØ§Ù…Ù„ØŒ ÙÙ‡Ù†Ø­ÙØ¸ ÙƒÙ„Ù‡ Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹
        result_df = df.copy()

    # ÙƒØ§Ù† Ø¨ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ø³Ø§Ø¨Ù‚Ø§Ù‹ØŒ Ù„ÙƒÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ø¸Ù‡ÙˆØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø­ØªÙ‰ Ù„Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ© (Ù…Ø«Ù„ IFERROR ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„)
    # filtered_results = result_df.dropna(subset=['rs_rating'])
    # Ø§Ù„Ø¢Ù† Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    filtered_results = result_df
    
    logger.info(f"ğŸ’¾ Saving {len(filtered_results)} RS records (Including NULLs for new stocks) to database...")
    
    # 5. Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Bulk Upsert
    from sqlalchemy.dialects.postgresql import insert
    
    # Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
    def clean_float(val):
        if pd.isna(val) or np.isinf(val):
            return None
        return float(val)

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³ (List of Dicts)
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ù†Ø§ Ø¨Ù†Ø®Ø²Ù† Ø§Ù„Ù€ Rank (1-99) Ù…ÙƒØ§Ù† Ø§Ù„Ù€ Return (%) Ù„ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙƒØªØ±ØªÙŠØ¨
    records_list = []
    for _, row in filtered_results.iterrows():
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªÙƒÙˆÙ† NaN (Ù„Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)
        rs_percentile_val = int(row['rs_rating']) if pd.notnull(row['rs_rating']) else None
        
        records_list.append({
            "date": row['date'],
            "symbol": row['symbol'],
            "rs_raw": clean_float(row['rs_raw']),
            "rs_percentile": rs_percentile_val,
            "return_3m": clean_float(row['rank_3m']),
            "return_6m": clean_float(row['rank_6m']),
            "return_9m": clean_float(row['rank_9m']),
            "return_12m": clean_float(row['rank_12m']),
            "created_at": datetime.datetime.now()
        })
        
    logger.info(f"ğŸ’¾ Prepared {len(records_list)} records for bulk upsert...")

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª (Chunks) Ù„Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¯Ø§ØªØ§Ø¨ÙŠØ²
    chunk_size = 5000
    for i in range(0, len(records_list), chunk_size):
        chunk = records_list[i:i + chunk_size]
        
        stmt = insert(RSDaily).values(chunk)
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ø²Ø§Ø¹: Ù„Ùˆ Ø§Ù„Ø±Ù…Ø² ÙˆØ§Ù„ØªØ§Ø±ÙŠØ® Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† -> Ø­Ø¯Ø« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        stmt = stmt.on_conflict_do_update(
            index_elements=['symbol', 'date'],
            set_={
                "rs_raw": stmt.excluded.rs_raw,
                "rs_percentile": stmt.excluded.rs_percentile,
                "return_3m": stmt.excluded.return_3m,
                "return_6m": stmt.excluded.return_6m,
                "return_9m": stmt.excluded.return_9m,
                "return_12m": stmt.excluded.return_12m
                # created_at Ù„Ø§ ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ø¹Ø´Ø§Ù† Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø£Ùˆ Ù…Ù…ÙƒÙ† Ù†Ø­Ø¯Ø«Ù‡ Ù„Ùˆ Ø¹Ø§ÙŠØ²ÙŠÙ†
            }
        )
        
        db.execute(stmt)
        db.commit() # Commit Ø¨Ø¹Ø¯ ÙƒÙ„ Chunk Ù„ØªØ®ÙÙŠÙ Ø§Ù„Ø¶ØºØ· ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù€ Timeout
        logger.info(f"âœ… Upserted chunk {i} to {i+chunk_size}")
        
    # db.commit() # Ø®Ù„Ø§Øµ Ø¹Ù…Ù„Ù†Ø§ commit Ø¬ÙˆÙ‡
    logger.info("âœ… RS Calculation V2 Completed Successfully!")

if __name__ == "__main__":
    # Test script standalone
    from app.core.database import SessionLocal
    db = SessionLocal()
    try:
        calculate_and_save_rs_v2(db)
    finally:
        db.close()
